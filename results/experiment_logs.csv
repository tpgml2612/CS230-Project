timestamp,architecture,hidden_dim,num_layers,dropout,learning_rate,batch_size,n_epochs,train_size,dev_size,final_train_loss,final_dev_loss,best_dev_loss,best_epoch,device,optimizer,scheduler,notes
2025-11-07_02-56-56,"lstm: LSTM(2, 64, num_layers=2, batch_first=True, dropout=0.3) â†’ fc: Sequential(  (0): Linear(in_features=64, out_features=64, bias=True)  (1): ReLU()  (2): Dropout(p=0.3, inplace=False)  (3): Linear(in_features=64, out_features=2, bias=True))",64,2,0.3,0.001,8,50,65,15,0.418693,1.311672,0.835103,16,mps,Adam,ReduceLROnPlateau, 
