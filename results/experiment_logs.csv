timestamp,architecture,hidden_dim,num_layers,dropout,learning_rate,batch_size,n_epochs,train_size,dev_size,final_train_loss,final_dev_loss,best_dev_loss,best_epoch,optimizer,notes
2025-11-07_12-08-20,"lstm: LSTM(2, 64, batch_first=True, dropout=0.3) → fc: Sequential(  (0): Linear(in_features=64, out_features=64, bias=True)  (1): ReLU()  (2): Dropout(p=0.3, inplace=False)  (3): Linear(in_features=64, out_features=2, bias=True)) → norm: LayerNorm((64,), eps=1e-05, elementwise_affine=True)",64,1,0.3,0.001,8,50,426,92,0.702152,1.341566,0.998132,2,Adam, 
2025-11-07_14-45-47,"lstm: LSTM(2, 64, num_layers=2, batch_first=True, dropout=0.3) → fc: Sequential(  (0): Linear(in_features=64, out_features=128, bias=True)  (1): ReLU()  (2): Dropout(p=0.3, inplace=False)  (3): Linear(in_features=128, out_features=64, bias=True)  (4): ReLU()  (5): Dropout(p=0.3, inplace=False)  (6): Linear(in_features=64, out_features=2, bias=True)) → norm: LayerNorm((64,), eps=1e-05, elementwise_affine=True)",64,2,0.3,0.001,8,50,426,92,1.007214,1.024324,0.976938,3,Adam, 
2025-11-07_15-35-03,"lstm: LSTM(2, 64, num_layers=2, batch_first=True, dropout=0.3) → fc: Sequential(  (0): Linear(in_features=64, out_features=128, bias=True)  (1): ReLU()  (2): Dropout(p=0.3, inplace=False)  (3): Linear(in_features=128, out_features=64, bias=True)  (4): ReLU()  (5): Dropout(p=0.3, inplace=False)  (6): Linear(in_features=64, out_features=2, bias=True)) → norm: LayerNorm((64,), eps=1e-05, elementwise_affine=True)",64,2,0.3,0.001,8,50,426,92,0.991216,0.981362,0.980815,4,Adam, 
2025-11-08_02-12-33,"lstm: LSTM(2, 64, num_layers=2, batch_first=True, dropout=0.3) → fc: Sequential(  (0): Linear(in_features=64, out_features=128, bias=True)  (1): ReLU()  (2): Linear(in_features=128, out_features=64, bias=True)  (3): ReLU()  (4): Linear(in_features=64, out_features=2, bias=True)) → norm: LayerNorm((64,), eps=1e-05, elementwise_affine=True)",64,2,0.3,0.001,8,50,2011,441,0.836411,0.800664,0.800664,50,Adam, 
2025-11-08_02-41-16,"lstm: LSTM(2, 64, num_layers=2, batch_first=True, dropout=0.3) → fc: Sequential(  (0): Linear(in_features=64, out_features=128, bias=True)  (1): ReLU()  (2): Linear(in_features=128, out_features=64, bias=True)  (3): ReLU()  (4): Linear(in_features=64, out_features=2, bias=True)) → norm: LayerNorm((64,), eps=1e-05, elementwise_affine=True)",64,2,0.3,0.001,8,50,2011,441,0.809016,0.833118,0.797282,85,Adam, 
2025-11-08_02-41-36,"lstm: LSTM(2, 64, num_layers=2, batch_first=True, dropout=0.3) → fc: Sequential(  (0): Linear(in_features=64, out_features=128, bias=True)  (1): ReLU()  (2): Linear(in_features=128, out_features=64, bias=True)  (3): ReLU()  (4): Linear(in_features=64, out_features=2, bias=True)) → norm: LayerNorm((64,), eps=1e-05, elementwise_affine=True)",64,2,0.3,0.001,8,50,2011,441,0.809016,0.833118,0.797282,85,Adam, 
2025-11-08_12-53-11,"lstm: LSTM(2, 64, num_layers=5, batch_first=True) → fc: Sequential(  (0): Linear(in_features=64, out_features=128, bias=True)  (1): ReLU()  (2): Linear(in_features=128, out_features=64, bias=True)  (3): ReLU()  (4): Linear(in_features=64, out_features=2, bias=True)) → norm: LayerNorm((64,), eps=1e-05, elementwise_affine=True)",64,5,0.3,0.001,8,50,2011,441,0.834636,0.802911,0.78318,90,Adam, 
