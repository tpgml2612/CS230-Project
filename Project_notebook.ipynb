{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1761864892592,
     "user": {
      "displayName": "정세희",
      "userId": "00114590619302027959"
     },
     "user_tz": 420
    },
    "id": "ORPXBBYXQrQA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1761864892593,
     "user": {
      "displayName": "정세희",
      "userId": "00114590619302027959"
     },
     "user_tz": 420
    },
    "id": "VeeKgccXRVh5"
   },
   "outputs": [],
   "source": [
    "def trim_and_flatten_data(haptic_df, robot_df):\n",
    "    # Haptic: 4, 5th columns (index 3, 4)\n",
    "    # Robot: 9, 10, 11th columns (index 8, 9, 10)\n",
    "    haptic_data = haptic_df.iloc[:, [3, 4]].values\n",
    "    robot_data = robot_df.iloc[:, [8, 9, 10]].values\n",
    "    \n",
    "    # Process NaN values by replacing them with zeros\n",
    "    haptic_data = np.nan_to_num(haptic_data, nan=0.0)\n",
    "    robot_data = np.nan_to_num(robot_data, nan=0.0)\n",
    "\n",
    "    # Trim to the length of the shorter dataset\n",
    "    min_len = min(len(haptic_data), len(robot_df))\n",
    "    haptic_data_trimmed = haptic_data[:min_len]\n",
    "    robot_data_trimmed = robot_data[:min_len]\n",
    "\n",
    "    # Combine and flatten\n",
    "    combined_features = np.concatenate((haptic_data_trimmed, robot_data_trimmed), axis=1)\n",
    "    return combined_features.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1761864892595,
     "user": {
      "displayName": "정세희",
      "userId": "00114590619302027959"
     },
     "user_tz": 420
    },
    "id": "b0C6s0F2RbbU"
   },
   "outputs": [],
   "source": [
    "def load_all_data(data_base_path):\n",
    "    base_path = Path(data_base_path) / \"DATA\"\n",
    "\n",
    "    all_X_data = []\n",
    "    all_y_data = []\n",
    "\n",
    "    METHOD_MAP = {'HAPTICS': 'H', 'NOhaptics': 'NH'}\n",
    "    TASK_MAP = {\n",
    "        5: ('pp1', 'PAP'), 6: ('pp1', 'PAP'),\n",
    "        7: ('pp2', 'PAPObstructed'), 8: ('pp2', 'PAPObstructed'),\n",
    "        9: ('pp3', 'Camera'), 10: ('pp3', 'Camera')\n",
    "    }\n",
    "\n",
    "    for p_id in range(1, 27): # 1~26\n",
    "\n",
    "        participant_str = f\"Participant_{p_id}\"\n",
    "        results_file = base_path / \"Haptic Data\" / participant_str / f\"{participant_str}_results.csv\"\n",
    "        \n",
    "        results_lookup = {}\n",
    "        try:\n",
    "            results_df = pd.read_csv(results_file)\n",
    "            for _, row in results_df.iterrows():\n",
    "                try:\n",
    "                    condition = row['Condition']\n",
    "                    subcondition = row['Subcondition']\n",
    "                    trial_str = str(row['Trial'])\n",
    "                    trial = int(re.search(r'^\\d+', trial_str).group())\n",
    "                    output_1 = pd.to_numeric(row['Sensor1 Mean'], errors='coerce')\n",
    "                    output_2 = pd.to_numeric(row['Sensor2 Mean'], errors='coerce')\n",
    "\n",
    "                    if pd.isna(output_1) or pd.isna(output_2):\n",
    "                        continue\n",
    "                    key = (condition, subcondition, trial)\n",
    "                    results_lookup[key] = (output_1, output_2)\n",
    "                except Exception:\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error in reading ({results_file}): {e}\")\n",
    "            continue\n",
    "        haptic_files_glob = glob.glob(str(base_path / \"Haptic Data\" / participant_str / \"*.csv\"))\n",
    "\n",
    "        for hfile_path in haptic_files_glob:\n",
    "            file_name = Path(hfile_path).name\n",
    "            match = re.match(r'(\\d+)_.*?_(HAPTICS|NOhaptics)_(\\d+)\\.csv', file_name)\n",
    "            \n",
    "            if not match:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                task_num = int(match.group(1))\n",
    "                method = match.group(2)\n",
    "                trial = int(match.group(3))\n",
    "                \n",
    "                if task_num not in TASK_MAP:\n",
    "                    continue\n",
    "\n",
    "                scenario_num, result_condition = TASK_MAP[task_num]\n",
    "                method_short = METHOD_MAP[method]\n",
    "\n",
    "                robot_pattern = (\n",
    "                    f\"{base_path}/Robot Data/{participant_str}/\"\n",
    "                    f\"*_task_{scenario_num}trial{trial}_method_{method_short}_participant_{p_id}.xlsx\"\n",
    "                )\n",
    "                robot_files = glob.glob(str(robot_pattern))\n",
    "\n",
    "                if not robot_files:\n",
    "                    print(f\" No matching robot file for: {robot_pattern}\")\n",
    "                    continue\n",
    "                output_key = (result_condition, method, trial)\n",
    "                if output_key not in results_lookup:\n",
    "                    continue\n",
    "\n",
    "                haptic_df = pd.read_csv(hfile_path)\n",
    "\n",
    "                if len(robot_files) > 1:\n",
    "                    df_list = [pd.read_excel(rf) for rf in robot_files]\n",
    "                    robot_df= pd.concat(df_list, ignore_index=True)\n",
    "                else:\n",
    "                    robot_df = pd.read_excel(robot_files[0])\n",
    "\n",
    "                flat_input_vector = trim_and_flatten_data(haptic_df, robot_df)\n",
    "\n",
    "                if flat_input_vector is not None:\n",
    "                    output_1, output_2 = results_lookup[output_key]\n",
    "                    output_vector = np.array([output_1, output_2])\n",
    "                    all_X_data.append(flat_input_vector)\n",
    "                    all_y_data.append(output_vector)\n",
    "            \n",
    "                print(f\" Success: participant {p_id} task {task_num}, method {method}, trial {trial}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error: {file_name} - {e}\")\n",
    "\n",
    "    max_len = max(len(x) for x in all_X_data)\n",
    "    \n",
    "    X_padded = np.array([np.pad(x, (0, max_len - len(x)), 'constant') for x in all_X_data])\n",
    "    y_array = np.array(all_y_data)\n",
    "\n",
    "    return X_padded, y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1761864892611,
     "user": {
      "displayName": "정세희",
      "userId": "00114590619302027959"
     },
     "user_tz": 420
    },
    "id": "0uyCSJqsReDc"
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, dev_size=0.125, random_state=42):\n",
    "    \"\"\"\n",
    "    데이터를 훈련, 개발, 테스트 세트로 분리합니다. (기본 70:10:20)\n",
    "    \"\"\"\n",
    "    if X.shape[0] == 0:\n",
    "        print(\"오류: 분리할 데이터가 없습니다.\")\n",
    "        return (np.array([]),)*6\n",
    "\n",
    "    # 1차 분리: 훈련+개발 (80%) / 테스트 (20%)\n",
    "    X_train_dev, X_test, y_train_dev, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 2차 분리: 훈련 (70%) / 개발 (10%)\n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "        X_train_dev, y_train_dev, test_size=dev_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    print(f\"데이터 분리 완료:\")\n",
    "    print(f\"  훈련 (Train)  : {X_train.shape}, {y_train.shape}\")\n",
    "    print(f\"  개발 (Dev)    : {X_dev.shape}, {y_dev.shape}\")\n",
    "    print(f\"  테스트 (Test) : {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_dev, X_test, y_train, y_dev, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1761864892613,
     "user": {
      "displayName": "정세희",
      "userId": "00114590619302027959"
     },
     "user_tz": 420
    },
    "id": "U28Z7oI_Rgzq"
   },
   "outputs": [],
   "source": [
    "def get_regularizer(config):\n",
    "    reg_type = config.get('regularizer_type', None)\n",
    "    l1_val = config.get('l1', 0.01)\n",
    "    l2_val = config.get('l2', 0.01)\n",
    "\n",
    "    if reg_type == 'l1': return regularizers.l1(l1_val)\n",
    "    elif reg_type == 'l2': return regularizers.l2(l2_val)\n",
    "    elif reg_type == 'l1_l2': return regularizers.l1_l2(l1=l1_val, l2=l2_val)\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1761864892630,
     "user": {
      "displayName": "정세희",
      "userId": "00114590619302027959"
     },
     "user_tz": 420
    },
    "id": "c1deJ4QPRjJq"
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape, model_config):\n",
    "    model = Sequential(name=\"Modular_DNN_Model\")\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "\n",
    "    hidden_layers = model_config.get('hidden_layers', [64, 32])\n",
    "    activation = model_config.get('activation', 'relu')\n",
    "    reg_obj = get_regularizer(model_config)\n",
    "\n",
    "    for units in hidden_layers:\n",
    "        model.add(Dense(units, activation=activation, kernel_regularizer=reg_obj))\n",
    "        if model_config.get('use_batch_norm', False):\n",
    "            model.add(BatchNormalization())\n",
    "        if model_config.get('dropout_rate', 0.0) > 0:\n",
    "            model.add(Dropout(model_config['dropout_rate']))\n",
    "\n",
    "    model.add(Dense(2, name='output')) # 2개 값 예측 (회귀)\n",
    "\n",
    "    print(\"모델 구성 완료:\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1761864892645,
     "user": {
      "displayName": "정세희",
      "userId": "00114590619302027959"
     },
     "user_tz": 420
    },
    "id": "nSZ381SORk7A"
   },
   "outputs": [],
   "source": [
    "def compile_and_train_model(model, X_train, y_train, X_val, y_val, train_config):\n",
    "    loss_function = train_config.get('loss', 'mean_squared_error')\n",
    "    learning_rate = train_config.get('learning_rate', 0.001)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    metrics_list = train_config.get('metrics', ['mean_absolute_error'])\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics_list)\n",
    "\n",
    "    print(\"\\n--- 모델 훈련 시작 ---\")\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=train_config.get('epochs', 50),\n",
    "        batch_size=train_config.get('batch_size', 32),\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"--- 모델 훈련 완료 ---\")\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1761864892662,
     "user": {
      "displayName": "정세희",
      "userId": "00114590619302027959"
     },
     "user_tz": 420
    },
    "id": "12Ex77R5Rqwn"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    if X_test.shape[0] == 0:\n",
    "        print(\"경고: 평가할 테스트 데이터가 없습니다.\")\n",
    "        return None\n",
    "\n",
    "    print(\"\\n--- 최종 모델 평가 (Test Set) ---\")\n",
    "    results = model.evaluate(X_test, y_test, verbose=1)\n",
    "    metric_names = model.metrics_names\n",
    "    for name, value in zip(metric_names, results):\n",
    "        print(f\"{name}: {value:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1761864892677,
     "user": {
      "displayName": "정세희",
      "userId": "00114590619302027959"
     },
     "user_tz": 420
    },
    "id": "b3LAlfZbRunr"
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    if not history:\n",
    "        print(\"시각화할 훈련 기록(history)이 없습니다.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Metric\n",
    "    metric_keys = [k for k in history.history.keys() if k not in ['loss', 'val_loss', 'lr']]\n",
    "    if metric_keys:\n",
    "        train_metric = metric_keys[0]\n",
    "        val_metric = f\"val_{train_metric}\"\n",
    "        if val_metric in history.history:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(history.history[train_metric], label=f'Train {train_metric}')\n",
    "            plt.plot(history.history[val_metric], label=f'Validation {val_metric}')\n",
    "            plt.title(f'Model Metric ({train_metric})')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Metric')\n",
    "            plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1761864892696,
     "user": {
      "displayName": "정세희",
      "userId": "00114590619302027959"
     },
     "user_tz": 420
    },
    "id": "_osqdpK8Rwnv"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    전체 파이프라인을 실행합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # === 설정 (Configuration) ===\n",
    "    # [검증 완료] 실제 프로젝트 경로\n",
    "    DATA_BASE_PATH_ROOT = r\".\"\n",
    "\n",
    "    # 모델 아키텍처 설정\n",
    "    MODEL_CONFIG = {\n",
    "        'hidden_layers': [128, 64, 32],\n",
    "        'activation': 'relu',\n",
    "        'regularizer_type': 'l2',\n",
    "        'l2': 0.001,\n",
    "        'use_batch_norm': True,\n",
    "        'dropout_rate': 0.2\n",
    "    }\n",
    "\n",
    "    # 훈련 설정\n",
    "    TRAIN_CONFIG = {\n",
    "        'learning_rate': 0.001,\n",
    "        'epochs': 100, # 126개 샘플은 적으니 epoch를 100~200 정도로 늘려도 좋습니다.\n",
    "        'batch_size': 16, # 샘플이 적으므로 배치 크기를 32보다 작게 (16) 조정\n",
    "        'loss': 'mean_squared_error',\n",
    "        'metrics': ['mean_absolute_error', tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    "    }\n",
    "    # ==========================\n",
    "\n",
    "    # 1. 데이터 로드 (검증된 함수 사용)\n",
    "    X, y = load_all_data(DATA_BASE_PATH_ROOT)\n",
    "\n",
    "    print(f\"전체 데이터셋 크기: X={X.shape}, y={y.shape}\")\n",
    "    print(f\"샘플 예시 (첫 5개):\")\n",
    "    for i in range(min(5, X.shape[0])):\n",
    "        print(f\" X[{i}]: {X[i][:10]}... , y[{i}]: {y[i]}\")\n",
    "        \n",
    "    # # 1-Extra. 데이터 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # # 2. 데이터 분리\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(X_scaled, y,0.15,0.15)\n",
    "\n",
    "    # if X_train.shape[0] == 0:\n",
    "    #     print(\"데이터 분리에 실패했습니다. (샘플 부족) 프로그램을 종료합니다.\")\n",
    "    #     return\n",
    "\n",
    "    # # 3. 모델 구축\n",
    "    input_shape = (X_train.shape[1],)\n",
    "    model = build_model(input_shape, MODEL_CONFIG)\n",
    "\n",
    "    # # 4. 모델 훈련\n",
    "    model, history = compile_and_train_model(\n",
    "        model, X_train, y_train, X_val, y_val, TRAIN_CONFIG\n",
    "    )\n",
    "\n",
    "    # # 5. 모델 평가\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "\n",
    "    # # 6. 결과 시각화\n",
    "    plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8241,
     "status": "ok",
     "timestamp": 1761864900936,
     "user": {
      "displayName": "정세희",
      "userId": "00114590619302027959"
     },
     "user_tz": 420
    },
    "id": "gFU47yZZSBIw",
    "outputId": "5a8bd775-395d-445f-9019-4fb3fd73e157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Success: participant 1 task 9, method NOhaptics, trial 1\n",
      " Success: participant 1 task 5, method HAPTICS, trial 10\n",
      " Success: participant 1 task 9, method NOhaptics, trial 4\n",
      " Success: participant 1 task 7, method HAPTICS, trial 5\n",
      " Success: participant 1 task 6, method NOhaptics, trial 4\n",
      " Success: participant 1 task 8, method NOhaptics, trial 4\n",
      " Success: participant 1 task 6, method NOhaptics, trial 7\n",
      " Success: participant 1 task 10, method HAPTICS, trial 2\n",
      " Success: participant 1 task 8, method NOhaptics, trial 2\n",
      " Success: participant 1 task 8, method NOhaptics, trial 5\n",
      " Success: participant 1 task 5, method HAPTICS, trial 7\n",
      " Success: participant 1 task 6, method NOhaptics, trial 2\n",
      " Success: participant 1 task 5, method HAPTICS, trial 6\n",
      " Success: participant 1 task 5, method HAPTICS, trial 2\n",
      " Success: participant 1 task 6, method NOhaptics, trial 9\n",
      " Success: participant 1 task 9, method NOhaptics, trial 5\n",
      " Success: participant 1 task 5, method HAPTICS, trial 5\n",
      " Success: participant 1 task 10, method HAPTICS, trial 3\n",
      " Success: participant 1 task 6, method NOhaptics, trial 10\n",
      " Success: participant 1 task 10, method HAPTICS, trial 5\n",
      " Success: participant 1 task 7, method HAPTICS, trial 1\n",
      " Success: participant 1 task 8, method NOhaptics, trial 1\n",
      " Success: participant 1 task 8, method NOhaptics, trial 3\n",
      " Success: participant 1 task 10, method HAPTICS, trial 4\n",
      " Success: participant 1 task 9, method NOhaptics, trial 2\n",
      " Success: participant 1 task 5, method HAPTICS, trial 1\n",
      " Success: participant 1 task 7, method HAPTICS, trial 2\n",
      " Success: participant 1 task 6, method NOhaptics, trial 6\n",
      " Success: participant 1 task 7, method HAPTICS, trial 3\n",
      " Success: participant 1 task 5, method HAPTICS, trial 4\n",
      " Success: participant 1 task 6, method NOhaptics, trial 5\n",
      " Success: participant 1 task 10, method HAPTICS, trial 1\n",
      " Success: participant 1 task 5, method HAPTICS, trial 9\n",
      " Success: participant 1 task 6, method NOhaptics, trial 3\n",
      " Success: participant 1 task 6, method NOhaptics, trial 1\n",
      " Success: participant 1 task 5, method HAPTICS, trial 8\n",
      " No matching robot file for: DATA/Robot Data/Participant_1/*_task_pp1trial8_method_NH_participant_1.xlsx\n",
      " Success: participant 1 task 7, method HAPTICS, trial 4\n",
      " Success: participant 1 task 5, method HAPTICS, trial 3\n",
      " Success: participant 2 task 9, method HAPTICS, trial 2\n",
      " Success: participant 2 task 5, method NOhaptics, trial 7\n",
      " Success: participant 2 task 8, method NOhaptics, trial 5\n",
      " Success: participant 2 task 9, method HAPTICS, trial 3\n",
      " Success: participant 2 task 7, method HAPTICS, trial 1\n",
      " Success: participant 2 task 5, method NOhaptics, trial 3\n",
      " Success: participant 2 task 5, method NOhaptics, trial 6\n",
      " Success: participant 2 task 6, method HAPTICS, trial 4\n",
      " Success: participant 2 task 6, method HAPTICS, trial 3\n",
      " Success: participant 2 task 6, method HAPTICS, trial 7\n",
      " Success: participant 2 task 9, method HAPTICS, trial 1\n",
      " Success: participant 2 task 9, method HAPTICS, trial 4\n",
      " Success: participant 2 task 10, method NOhaptics, trial 3\n",
      " Success: participant 2 task 10, method NOhaptics, trial 2\n",
      " Success: participant 2 task 6, method HAPTICS, trial 6\n",
      " Success: participant 2 task 7, method HAPTICS, trial 5\n",
      " Success: participant 2 task 7, method HAPTICS, trial 2\n",
      " Success: participant 2 task 6, method HAPTICS, trial 9\n",
      " Success: participant 2 task 6, method HAPTICS, trial 1\n",
      " Success: participant 2 task 7, method HAPTICS, trial 4\n",
      " Success: participant 2 task 6, method HAPTICS, trial 5\n",
      " Success: participant 2 task 6, method HAPTICS, trial 2\n",
      " Success: participant 2 task 5, method NOhaptics, trial 5\n",
      " Success: participant 2 task 8, method NOhaptics, trial 1\n",
      " Success: participant 2 task 5, method NOhaptics, trial 10\n",
      " Success: participant 2 task 7, method HAPTICS, trial 3\n",
      " Success: participant 2 task 8, method NOhaptics, trial 4\n",
      " Success: participant 2 task 6, method HAPTICS, trial 8\n",
      " Success: participant 2 task 5, method NOhaptics, trial 9\n",
      " Success: participant 2 task 10, method NOhaptics, trial 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[363]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m warnings.filterwarnings(\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, category=\u001b[38;5;167;01mUserWarning\u001b[39;00m, module=\u001b[33m'\u001b[39m\u001b[33mopenpyxl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[362]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     21\u001b[39m TRAIN_CONFIG = {\n\u001b[32m     22\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0.001\u001b[39m,\n\u001b[32m     23\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m100\u001b[39m, \u001b[38;5;66;03m# 126개 샘플은 적으니 epoch를 100~200 정도로 늘려도 좋습니다.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mmean_absolute_error\u001b[39m\u001b[33m'\u001b[39m, tf.keras.metrics.RootMeanSquaredError(name=\u001b[33m'\u001b[39m\u001b[33mrmse\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m     27\u001b[39m }\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# ==========================\u001b[39;00m\n\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 1. 데이터 로드 (검증된 함수 사용)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m X, y = \u001b[43mload_all_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_BASE_PATH_ROOT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m전체 데이터셋 크기: X=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, y=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m샘플 예시 (첫 5개):\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[355]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mload_all_data\u001b[39m\u001b[34m(data_base_path)\u001b[39m\n\u001b[32m     77\u001b[39m     robot_df= pd.concat(df_list, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     robot_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrobot_files\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m flat_input_vector = trim_and_flatten_data(haptic_df, robot_df)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flat_input_vector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sehui\\.conda\\envs\\CS230\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:508\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     data = \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    534\u001b[39m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sehui\\.conda\\envs\\CS230\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1616\u001b[39m, in \u001b[36mExcelFile.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m   1576\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\n\u001b[32m   1577\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1578\u001b[39m     sheet_name: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1596\u001b[39m     **kwds,\n\u001b[32m   1597\u001b[39m ) -> DataFrame | \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] | \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[32m   1598\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1599\u001b[39m \u001b[33;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[32m   1600\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1614\u001b[39m \u001b[33;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[32m   1615\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1619\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1620\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1621\u001b[39m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m=\u001b[49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1623\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1636\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sehui\\.conda\\envs\\CS230\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:778\u001b[39m, in \u001b[36mBaseExcelReader.parse\u001b[39m\u001b[34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[39m\n\u001b[32m    775\u001b[39m     sheet = \u001b[38;5;28mself\u001b[39m.get_sheet_by_index(asheetname)\n\u001b[32m    777\u001b[39m file_rows_needed = \u001b[38;5;28mself\u001b[39m._calc_rows(header, index_col, skiprows, nrows)\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_sheet_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_rows_needed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sheet, \u001b[33m\"\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    780\u001b[39m     \u001b[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n\u001b[32m    781\u001b[39m     sheet.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sehui\\.conda\\envs\\CS230\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:615\u001b[39m, in \u001b[36mOpenpyxlReader.get_sheet_data\u001b[39m\u001b[34m(self, sheet, file_rows_needed)\u001b[39m\n\u001b[32m    613\u001b[39m data: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar]] = []\n\u001b[32m    614\u001b[39m last_row_with_data = -\u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# trim trailing empty elements\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sehui\\.conda\\envs\\CS230\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85\u001b[39m, in \u001b[36mReadOnlyWorksheet._cells_by_row\u001b[39m\u001b[34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_source() \u001b[38;5;28;01mas\u001b[39;00m src:\n\u001b[32m     78\u001b[39m     parser = WorkSheetParser(src,\n\u001b[32m     79\u001b[39m                              \u001b[38;5;28mself\u001b[39m._shared_strings,\n\u001b[32m     80\u001b[39m                              data_only=\u001b[38;5;28mself\u001b[39m.parent.data_only,\n\u001b[32m     81\u001b[39m                              epoch=\u001b[38;5;28mself\u001b[39m.parent.epoch,\n\u001b[32m     82\u001b[39m                              date_formats=\u001b[38;5;28mself\u001b[39m.parent._date_formats,\n\u001b[32m     83\u001b[39m                              timedelta_formats=\u001b[38;5;28mself\u001b[39m.parent._timedelta_formats)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_row\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sehui\\.conda\\envs\\CS230\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:156\u001b[39m, in \u001b[36mWorkSheetParser.parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    137\u001b[39m properties = {\n\u001b[32m    138\u001b[39m     PRINT_TAG: (\u001b[33m'\u001b[39m\u001b[33mprint_options\u001b[39m\u001b[33m'\u001b[39m, PrintOptions),\n\u001b[32m    139\u001b[39m     MARGINS_TAG: (\u001b[33m'\u001b[39m\u001b[33mpage_margins\u001b[39m\u001b[33m'\u001b[39m, PageMargins),\n\u001b[32m   (...)\u001b[39m\u001b[32m    151\u001b[39m \n\u001b[32m    152\u001b[39m }\n\u001b[32m    154\u001b[39m it = iterparse(\u001b[38;5;28mself\u001b[39m.source) \u001b[38;5;66;03m# add a finaliser to close the source when this becomes possible\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtag_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtag\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtag_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sehui\\.conda\\envs\\CS230\\Lib\\xml\\etree\\ElementTree.py:1253\u001b[39m, in \u001b[36miterparse.<locals>.iterator\u001b[39m\u001b[34m(source)\u001b[39m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m pullparser.read_events()\n\u001b[32m   1252\u001b[39m \u001b[38;5;66;03m# load event buffer\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1253\u001b[39m data = \u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sehui\\.conda\\envs\\CS230\\Lib\\zipfile.py:982\u001b[39m, in \u001b[36mZipExtFile.read\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m    980\u001b[39m \u001b[38;5;28mself\u001b[39m._offset = \u001b[32m0\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    983\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[32m    984\u001b[39m         \u001b[38;5;28mself\u001b[39m._readbuffer = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sehui\\.conda\\envs\\CS230\\Lib\\zipfile.py:1058\u001b[39m, in \u001b[36mZipExtFile._read1\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compress_type == ZIP_DEFLATED:\n\u001b[32m   1057\u001b[39m     n = \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m.MIN_READ_SIZE)\n\u001b[32m-> \u001b[39m\u001b[32m1058\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decompressor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1059\u001b[39m     \u001b[38;5;28mself\u001b[39m._eof = (\u001b[38;5;28mself\u001b[39m._decompressor.eof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1060\u001b[39m                  \u001b[38;5;28mself\u001b[39m._compress_left <= \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m   1061\u001b[39m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decompressor.unconsumed_tail)\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOM22h0X2OWDWNoH0YkCQnE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CS230",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
